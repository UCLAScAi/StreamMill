Jan 15, 2008. 
Version 1.0.1

Table of Contents:

1. Introduction
2. Install
3. Parameters
3. How to use the tools
   3.1. DTV
   3.2  DFV
   3.3. SWIM (memory-based)
   3.4. SWIM (disk-based)
   3.5. Misc
        3.5.1. asc2bin
        3.5.2. bin2asc
4. Common issues
5. Examples

****************************************
1. Introduction

SWIM (Sliding Window Incremental Miner) is based on two fast verifers. 
http://wis.cs.ucla.edu/swim/index.htm

Implemented by:
Barzan Mozafari (barzan@cs.ucla.edu)
http://www.cs.ucla.edu/~barzan

This implementation is based on the following paper:
Barzan Mozafari, Hetal Thakkar, Carlo Zaniolo. Verifying and Mining Frequent Patterns from Large Windows over Data Streams. In the Proceedings of the 24th International Conference on Data Engineering (ICDE 2008), Cancun, Mexico, April 7-12, 2008.

****************************************
2. Install

After unpacking the tar file, you need to compile the packages as follows:

In order to compile DTV or DFV, 
$ cd classic/
$ make

and in order to install SWIM,
$ cd swim
$ make

****************************************
3. Parameters

The following parameters are used as the arguments that some of the tools in this package will accept.

	trans_avg_len 
		The average length of the transactions in the datatbase.
	
	window_size 
		The number of the input tuples (=transactions) per window.	

	slide_size 
		The number of the input tuples (=transactions) per slide. The slide size should be a divisor of the window size.	

	L_delay_max
		The maximum tolerated delay for a new pattern to be reported. This maximum delay is in terms of the  number of slides that the window moves. Therefore, e.g. if window_size=10*slide_size, then L_delay_max can be 0,1,2,...,9 with 9 allowing the maximum delay and consequently the maximum efficiency, i.e. a new pattern MAY be reported after 9 slides.

	no_items 
		The number of different singles items, e.g. 1000. Notice that this number must be larger than the maximum single item that has appeared in the input, because the single items start from 0 rather than 1. So if we have 1000 in the input transactions, no_items=1001.

	[0=best,1=worst]
		In a 2-pass algorithm, a 0 value for this parameter results in an decsending order of single items (in the FP-tree) based on their frequencies. Likewise, a value of 1 for this parameter causes an acsending order of item based on their frequencies. Basically, this parameter only affects the size of the FP-tree as follows: The topper high-frequency items appear, the more compact the result FP-tree. According to our experiments, this has only affects the tree size by a constanct factor, i.e. the subsequent conditionalized trees and running times are affected only by the same factor too (approximately). 
Notice: Since most of the algorithms in this project are single-pass, this parameter has no effect.

	min_supp_10000 
		This is the minimum support given in 10000'th as an integer. For example for a 0.5% threshold, this parameter should be set to 50. 

	fname_asci
		This is the input file name in ASCI format (containing the transactional database) which will be interpreted relatively to the current working directory. The input file format is IBM Guest generator, i.e. each line contains: Tid Tid Len Item_1 Item_2 ... Item_Len. As an example, see the file `classic/sample.asci` .

	instream
		This is the name of the input stream file, in binary format, that contains the transactions of the stream. As an example, see the file `swim/sample-ibm.bin` which can be built from file `swim/sample-ibm.asci` using asc2bin tool. For more details see the Examples at the end of this README file.

	outarch
		This is the name of the output file, in binary format, that will be used to archive the transactions of the incoming stream. This file will be generated by the tools and does not have to be provided by user.

****************************************
3. How to use the tools

In this section, for each specific tool we separately explain the set and the order of the arguments that they accept. Typically, the usage syntax is printed if the programs are invoked without any arguments.

****************************************
3.1. DTV 

This is in fact the Hybrid verifier that has been implemented in rec_verifier.
Usage: 
$ classic/rec_verifier trans_avg_len window_size no_items [0=best,1=worst] min_supp_10000 fname_asci


****************************************
3.2. DFV

This algorithm (Depth-First Verifier) is the following `verifier'.
Usage:
$ classic/verifier trans_avg_len window_size no_items [0=best,1=worst] min_supp_10000 fname_asci

****************************************
3.3. SWIM (memory-based)

Usage: 
$ swim/mem-delayed trans_avg_len window_size slide_size L_delay_max no_items min_supp_10000 instream

****************************************
3.4. SWIM (disk-based)

Usage:
$ swim/disk-delayed trans_avg_len window_size slide_size L_delay_max no_items min_supp_10000 instream outarch

****************************************
3.5. Misc

3.5.1. asc2bin: This is a tool to convert the IBM transactional database format from ASCII to binary.

Usage:
$ swim/asc2bin inputfile outputfile

3.5.2. bin2asc: This is a tool reversing what asc2bin does.

Usage: 
$ swim/bin2asc inputfile outputfile

****************************************
4. Common issues

I-1. Segmentation fault.
  There are many reasons that can cause a run-time segmentation fault error. The most important ones relate to the input paramaters inconsistent with the input file. The following represent examples of more common mistakes:

- trans_avg_len that is smaller than the actual average of the transactions in the file. If the actual average of the transactions is a fractional number take a roof rather than a ceil. Also, do not try to provide a very loose upperbound of the transactions' length as you may easily ran out memory. The SWIM and its underlying verifiers use the input parameters to allocate memory before the execution. 

- no_items that is smaller than or equal to the largest item number that exists in the input transactions.

- Providing an ascii input file where a binary file is expected.

I-2. In the classic/ we convert the output such that the item numbers range from 1 to item_no while in the swim/ we deal with the single items as they are, meaning we do not make any conversions: They range from 0 ti item_no-1;

****************************************
5. Examples 

$ classic/rec_verifier 3 3 5 0 100 classic/sample.asci

$ classic/verifier 3 3 5 0 100 classic/sample.asci

$ swim/mem-delayed 23 5000 1000 4 1000 100 swim/sample-ibm.bin

$ swim/disk-delayed 23 5000 1000 4 1000 100 swim/sample-ibm.bin  swim/myarch

$ swim/asc2bin swim/sample-ibm.asci swim/sample-ibm.bin

$ swim/bin2asc swim/sample-ibm.bin swim/sample-ibm.asci


